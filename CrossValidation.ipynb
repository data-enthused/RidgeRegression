{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import pandas as pd \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = pd.DataFrame(load_boston().data, columns=load_boston().feature_names)\n",
    "boston_dataset['MEDV'] = load_boston().target\n",
    "dataframe_size = int(len(boston_dataset) * 0.8)\n",
    "x_train=boston_dataset.RM[:dataframe_size]\n",
    "x_test=boston_dataset.RM[dataframe_size:]\n",
    "y_train=boston_dataset.MEDV[:dataframe_size]\n",
    "y_test=boston_dataset.MEDV[dataframe_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomialRegression(H,Y):\n",
    "    W = np.dot(np.dot((np.linalg.inv(np.dot(H.T, H))), H.T),Y) #Polynomial Regrssion function\n",
    "    return W\n",
    "\n",
    "def GradientDescent(H,Y,lamda):\n",
    "    n, m = H.shape\n",
    "    I = np.identity(m)\n",
    "    coeff=np.dot(np.dot(np.linalg.inv(np.dot(H.T, H) + lamda * I), H.T), Y)\n",
    "    return coeff\n",
    "\n",
    "def CrossValidation(train_copy,lamdavalue):\n",
    "    fold_size = int(len(train_copy) * 0.2)\n",
    "    fold=0\n",
    "    rss=0\n",
    "    for i in range(1,6):\n",
    "        validation_set= train_copy[fold:i*fold_size]\n",
    "        train_set=train_copy.drop(train_copy[fold:i*fold_size].index,axis=0)\n",
    "        W=GradientDescent(train_set.RM,train_set.MEDV,lamdavalue)\n",
    "        #print(W)\n",
    "        rss+=sum((validation_set.MEDV - np.dot(validation_set.RM,W) )** 2)\n",
    "        fold=i*fold_size\n",
    "        i+=1\n",
    "    #print((rss/5))\n",
    "    return ((rss/5))\n",
    "\n",
    "\n",
    "\n",
    "def RidgeRegression(train_copy):\n",
    "    validation_Error=[]\n",
    "    bestfit_W=[]\n",
    "    bestfit_lamda=0\n",
    "    \n",
    "    lamdavalue = [(10 ** (-10)),(10 ** (-8)),(10 ** (-6)),(10 ** (-4)),(10 ** (-2)),(10 ** (-1)),10,(10 ** (2))]\n",
    "    for i in range(0,len(lamdavalue)):\n",
    "        (avg_validationError) = CrossValidation(train_copy, lamdavalue[i])\n",
    "        validation_Error.append(avg_validationError)\n",
    "        if min(validation_Error) == avg_validationError:\n",
    "            bestfit_lamda = lamdavalue[i]\n",
    "    result = pd.DataFrame({'validationError':validation_Error,'lamdaValue':lamdavalue})\n",
    "    return (bestfit_lamda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd order Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coeffecients for polynomial regression [-2.03391734  0.91107707]\n",
      "The coeffecients for ridge regression: [-1.94078329  0.89693875]\n",
      "The best fit lamda value: 10\n",
      "MSE for polynomial regression: 68.7444509199822\n",
      "MSE for ridge regression: 68.91697581509428\n"
     ]
    }
   ],
   "source": [
    "H_secondOrder = pd.concat([x_train, x_train **2], axis=1) \n",
    "H_Test2 = pd.concat([x_test, x_test **2], axis=1)\n",
    "training_2ndOrder = pd.concat([H_secondOrder, y_train], axis=1)\n",
    "training_2ndOrder=training_2ndOrder.sample(frac=1)\n",
    "\n",
    "W_2 = polynomialRegression(H_secondOrder,y_train)# Coeffecients for polynomial regression\n",
    "print(\"The coeffecients for polynomial regression\" , W_2)\n",
    "bestfit_lamda2 = RidgeRegression(training_2ndOrder)\n",
    "bestfit_W2 = GradientDescent(H_secondOrder,y_train,bestfit_lamda2) # trains model to get Coeffecients for the best fit lamda\n",
    "print(\"The coeffecients for ridge regression: {0}\\nThe best fit lamda value: {1}\".format(bestfit_W2,bestfit_lamda2))\n",
    "\n",
    "MSE_2ndPolynomial = (sum((y_test-np.dot(H_Test2,W_2)) ** 2))/len(x_test)\n",
    "MSE_2ndRidge = (sum((y_test-np.dot(H_Test2,bestfit_W2)) ** 2))/len(x_test)\n",
    "print(\"MSE for polynomial regression: {0}\\nMSE for ridge regression: {1}\".format(MSE_2ndPolynomial,MSE_2ndRidge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9th Order Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coeffecients for polynomial regression [-3.78781470e+03  5.90395778e+03 -3.85618187e+03  1.39273241e+03\n",
      " -3.06057745e+02  4.20786020e+01 -3.54558909e+00  1.67830201e-01\n",
      " -3.42435078e-03]\n",
      "The coeffecients for ridge regression: [ 8.75280921e+00  1.04141918e+01  3.77178123e+00 -8.34221523e+00\n",
      "  3.51998148e+00 -6.98761529e-01  7.35635212e-02 -3.93504635e-03\n",
      "  8.29065261e-05]\n",
      "The best fit lamda value: 0.1\n",
      "MSE for polynomial regression: 50.103138834675036\n",
      "MSE for ridge regression: 63.23984577079102\n"
     ]
    }
   ],
   "source": [
    "H_ninethOrder = pd.concat([x_train ** i for i in range(1,10) ],axis=1) \n",
    "H_Test9 = pd.concat([x_test ** i for i in range(1,10) ],axis=1)\n",
    "training_9thOrder = pd.concat([H_ninethOrder, y_train], axis=1)\n",
    "training_9thOrder=training_9thOrder.sample(frac=1)\n",
    "\n",
    "W_9 = polynomialRegression(H_ninethOrder,y_train)# Coeffecients for polynomial regression\n",
    "print(\"The coeffecients for polynomial regression\" , W_9)\n",
    "bestfit_lamda9 = RidgeRegression(training_9thOrder)\n",
    "bestfit_W9 = GradientDescent(H_ninethOrder,y_train,bestfit_lamda9) # trains model to get Coeffecients for the best fit lamda\n",
    "print(\"The coeffecients for ridge regression: {0}\\nThe best fit lamda value: {1}\".format(bestfit_W9,bestfit_lamda9))\n",
    "\n",
    "MSE_9thPolynomial = (sum((y_test-np.dot(H_Test9,W_9)) ** 2))/len(x_test)\n",
    "MSE_9thRidge = (sum((y_test-np.dot(H_Test9,bestfit_W9)) ** 2))/len(x_test)\n",
    "print(\"MSE for polynomial regression: {0}\\nMSE for ridge regression: {1}\".format(MSE_9thPolynomial,MSE_9thRidge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
